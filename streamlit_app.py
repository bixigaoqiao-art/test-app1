import streamlit as st
import numpy as np
from PIL import Image
import cv2

def separate_colors(image, target_color):
    """ç‰¹å®šã®è‰²ã‚’å¼·èª¿ã—ã¦åˆ†é›¢"""
    img_array = np.array(image)
    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
    
    # è‰²ç›¸ç¯„å›²ã®å®šç¾©ï¼ˆHSVç©ºé–“ï¼‰
    color_ranges = {
        'èµ¤': [(0, 100, 100), (10, 255, 255), (170, 100, 100), (180, 255, 255)],
        'ç·‘': [(40, 100, 100), (80, 255, 255)],
        'é’': [(100, 100, 100), (130, 255, 255)],
        'é»„': [(20, 100, 100), (40, 255, 255)],
        'ç´«': [(130, 100, 100), (160, 255, 255)],
        'ã‚ªãƒ¬ãƒ³ã‚¸': [(10, 100, 100), (20, 255, 255)],
    }
    
    # ãƒã‚¹ã‚¯ã®ä½œæˆ
    if target_color == 'èµ¤':
        mask1 = cv2.inRange(hsv, color_ranges['èµ¤'][0], color_ranges['èµ¤'][1])
        mask2 = cv2.inRange(hsv, color_ranges['èµ¤'][2], color_ranges['èµ¤'][3])
        mask = cv2.bitwise_or(mask1, mask2)
    else:
        mask = cv2.inRange(hsv, color_ranges[target_color][0], color_ranges[target_color][1])
    
    # çµæœç”»åƒã®ä½œæˆ
    result = img_array.copy()
    result[mask == 0] = result[mask == 0] // 3  # å¯¾è±¡å¤–ã®è‰²ã‚’æš—ãã™ã‚‹
    
    return Image.fromarray(result)

def enhance_contrast(image, target_colors):
    """è¤‡æ•°ã®è‰²ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·èª¿"""
    img_array = np.array(image)
    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
    
    color_mappings = {
        'èµ¤â†’ãƒã‚¼ãƒ³ã‚¿': [(0, 180, 170, 255), (255, 0, 255)],
        'ç·‘â†’ã‚·ã‚¢ãƒ³': [(40, 80, 100, 255), (0, 255, 255)],
        'èµ¤â†’é’': [(0, 10, 100, 255), (0, 0, 255), (170, 180, 100, 255)],
        'ç·‘â†’é»„': [(40, 80, 100, 255), (255, 255, 0)],
    }
    
    result = img_array.copy()
    
    for mapping in target_colors:
        if mapping in color_mappings:
            data = color_mappings[mapping]
            if mapping == 'èµ¤â†’é’':
                # èµ¤ã®2ã¤ã®ç¯„å›²ã‚’å‡¦ç†
                mask1 = cv2.inRange(hsv, (data[0][0], data[0][2], data[0][3], 0), 
                                   (data[0][1], 255, 255, 0))
                mask2 = cv2.inRange(hsv, (data[2][0], data[2][2], data[2][3], 0), 
                                   (data[2][1], 255, 255, 0))
                mask = cv2.bitwise_or(mask1, mask2)
                result[mask > 0] = data[1]
            else:
                mask = cv2.inRange(hsv, (data[0][0], data[0][2], data[0][3], 0), 
                                  (data[0][1], 255, 255, 0))
                result[mask > 0] = data[1]
    
    return Image.fromarray(result)

def apply_daltonization(image, cvd_type):
    """è‰²è¦šç•°å¸¸ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨è£œæ­£"""
    img_array = np.array(image).astype(float) / 255.0
    
    # å¤‰æ›è¡Œåˆ—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if cvd_type == '1å‹ï¼ˆèµ¤ï¼‰':
        # ãƒ—ãƒ­ã‚¿ãƒãƒ”ã‚¢ï¼ˆèµ¤éŒä½“æ¬ æï¼‰
        transform = np.array([
            [0.567, 0.433, 0.000],
            [0.558, 0.442, 0.000],
            [0.000, 0.242, 0.758]
        ])
    elif cvd_type == '2å‹ï¼ˆç·‘ï¼‰':
        # ãƒ‡ãƒ¥ãƒ¼ã‚¿ãƒãƒ”ã‚¢ï¼ˆç·‘éŒä½“æ¬ æï¼‰
        transform = np.array([
            [0.625, 0.375, 0.000],
            [0.700, 0.300, 0.000],
            [0.000, 0.300, 0.700]
        ])
    else:  # 3å‹ï¼ˆé’ï¼‰
        # ãƒˆãƒªã‚¿ãƒãƒ”ã‚¢ï¼ˆé’éŒä½“æ¬ æï¼‰
        transform = np.array([
            [0.950, 0.050, 0.000],
            [0.000, 0.433, 0.567],
            [0.000, 0.475, 0.525]
        ])
    
    # ç”»åƒã‚’å¤‰æ›
    h, w = img_array.shape[:2]
    img_flat = img_array.reshape(-1, 3)
    simulated_flat = np.dot(img_flat, transform.T)
    simulated = simulated_flat.reshape(h, w, 3)
    
    # è£œæ­£ï¼ˆå·®åˆ†ã‚’å¼·èª¿ï¼‰
    error = img_array - simulated
    corrected = img_array + error * 1.5
    corrected = np.clip(corrected, 0, 1)
    
    return Image.fromarray((corrected * 255).astype(np.uint8))

# Streamlitã‚¢ãƒ—ãƒª
st.title('ğŸ¨ è‰²è¦šç•°å¸¸æ”¯æ´ãƒ„ãƒ¼ãƒ«')
st.write('ç”»åƒã®è‰²ã‚’åˆ†é›¢ãƒ»å¼·èª¿ã—ã¦ã€è‰²ã®è­˜åˆ¥ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™')

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header('è¨­å®š')
mode = st.sidebar.radio(
    'å‡¦ç†ãƒ¢ãƒ¼ãƒ‰',
    ['è‰²ã®åˆ†é›¢', 'ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿', 'è‰²è¦šè£œæ­£']
)

# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader('ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰', type=['png', 'jpg', 'jpeg'])

if uploaded_file:
    image = Image.open(uploaded_file).convert('RGB')
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader('å…ƒç”»åƒ')
        st.image(image, use_container_width=True)
    
    with col2:
        st.subheader('å‡¦ç†å¾Œ')
        
        if mode == 'è‰²ã®åˆ†é›¢':
            target = st.sidebar.selectbox(
                'åˆ†é›¢ã™ã‚‹è‰²',
                ['èµ¤', 'ç·‘', 'é’', 'é»„', 'ç´«', 'ã‚ªãƒ¬ãƒ³ã‚¸']
            )
            result = separate_colors(image, target)
            st.image(result, use_container_width=True)
            st.info(f'{target}è‰²ã®é ˜åŸŸã‚’å¼·èª¿è¡¨ç¤ºã—ã¦ã„ã¾ã™')
            
        elif mode == 'ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿':
            mappings = st.sidebar.multiselect(
                'è‰²ã®å¤‰æ›',
                ['èµ¤â†’ãƒã‚¼ãƒ³ã‚¿', 'ç·‘â†’ã‚·ã‚¢ãƒ³', 'èµ¤â†’é’', 'ç·‘â†’é»„'],
                default=['èµ¤â†’ãƒã‚¼ãƒ³ã‚¿']
            )
            if mappings:
                result = enhance_contrast(image, mappings)
                st.image(result, use_container_width=True)
                st.info('é¸æŠã—ãŸè‰²ã‚’è­˜åˆ¥ã—ã‚„ã™ã„è‰²ã«å¤‰æ›ã—ã¦ã„ã¾ã™')
            else:
                st.image(image, use_container_width=True)
                
        else:  # è‰²è¦šè£œæ­£
            cvd = st.sidebar.selectbox(
                'è‰²è¦šç•°å¸¸ã®ã‚¿ã‚¤ãƒ—',
                ['1å‹ï¼ˆèµ¤ï¼‰', '2å‹ï¼ˆç·‘ï¼‰', '3å‹ï¼ˆé’ï¼‰']
            )
            result = apply_daltonization(image, cvd)
            st.image(result, use_container_width=True)
            st.info(f'{cvd}è‰²è¦šç•°å¸¸ã«å¯¾å¿œã—ãŸè£œæ­£ã‚’é©ç”¨ã—ã¦ã„ã¾ã™')
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    if st.button('å‡¦ç†ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰'):
        result.save('processed_image.png')
        with open('processed_image.png', 'rb') as f:
            st.download_button(
                'ğŸ’¾ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰',
                f,
                file_name='processed_image.png',
                mime='image/png'
            )

else:
    st.info('ğŸ‘† ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„')
    
# èª¬æ˜
with st.expander('â„¹ï¸ å„ãƒ¢ãƒ¼ãƒ‰ã®èª¬æ˜'):
    st.markdown('''
    **è‰²ã®åˆ†é›¢**: ç‰¹å®šã®è‰²ã ã‘ã‚’å¼·èª¿è¡¨ç¤ºã—ã€ä»–ã®è‰²ã‚’æš—ãã™ã‚‹ã“ã¨ã§è‰²ã®è­˜åˆ¥ã‚’å®¹æ˜“ã«ã—ã¾ã™
    
    **ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿**: æ··åŒã—ã‚„ã™ã„è‰²ã‚’ã€ã‚ˆã‚Šè­˜åˆ¥ã—ã‚„ã™ã„è‰²ã«å¤‰æ›ã—ã¾ã™
    - èµ¤â†’ãƒã‚¼ãƒ³ã‚¿: èµ¤ã‚’é®®ã‚„ã‹ãªãƒã‚¼ãƒ³ã‚¿ã«
    - ç·‘â†’ã‚·ã‚¢ãƒ³: ç·‘ã‚’æ˜ã‚‹ã„ã‚·ã‚¢ãƒ³ã«
    - èµ¤â†’é’: èµ¤ã‚’é’ã«å¤‰æ›ï¼ˆèµ¤ç·‘æ··åŒå¯¾ç­–ï¼‰
    - ç·‘â†’é»„: ç·‘ã‚’æ˜ã‚‹ã„é»„è‰²ã«
    
    **è‰²è¦šè£œæ­£**: è‰²è¦šç•°å¸¸ã®ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè£œæ­£ã‚’é©ç”¨ã—ã€è‰²ã®é•ã„ã‚’å¼·èª¿ã—ã¾ã™
    - 1å‹ï¼ˆèµ¤ï¼‰: èµ¤éŒä½“ã®æ©Ÿèƒ½ä¸å…¨
    - 2å‹ï¼ˆç·‘ï¼‰: ç·‘éŒä½“ã®æ©Ÿèƒ½ä¸å…¨ï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ï¼‰
    - 3å‹ï¼ˆé’ï¼‰: é’éŒä½“ã®æ©Ÿèƒ½ä¸å…¨
    ''')