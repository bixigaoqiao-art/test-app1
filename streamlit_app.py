import streamlit as st
import numpy as np
from PIL import Image

def rgb_to_hsv(rgb):
    """RGBã‚’HSVã«å¤‰æ›"""
    rgb = rgb.astype(float) / 255.0
    r, g, b = rgb[..., 0], rgb[..., 1], rgb[..., 2]
    
    maxc = np.max(rgb, axis=-1)
    minc = np.min(rgb, axis=-1)
    v = maxc
    
    deltac = maxc - minc
    s = np.where(maxc != 0, deltac / maxc, 0)
    
    rc = np.where(deltac != 0, (maxc - r) / deltac, 0)
    gc = np.where(deltac != 0, (maxc - g) / deltac, 0)
    bc = np.where(deltac != 0, (maxc - b) / deltac, 0)
    
    h = np.zeros_like(maxc)
    h = np.where((maxc == r) & (deltac != 0), bc - gc, h)
    h = np.where((maxc == g) & (deltac != 0), 2.0 + rc - bc, h)
    h = np.where((maxc == b) & (deltac != 0), 4.0 + gc - rc, h)
    h = (h / 6.0) % 1.0
    h = h * 180
    
    return np.stack([h, s * 255, v * 255], axis=-1)

def separate_colors(image, target_color):
    """ç‰¹å®šã®è‰²ã‚’å¼·èª¿ã—ã¦åˆ†é›¢"""
    img_array = np.array(image)
    hsv = rgb_to_hsv(img_array)
    h, s, v = hsv[..., 0], hsv[..., 1], hsv[..., 2]
    
    # è‰²ç›¸ç¯„å›²ã®å®šç¾©
    color_ranges = {
        'èµ¤': [(0, 10), (170, 180)],
        'ç·‘': [(40, 80)],
        'é’': [(100, 130)],
        'é»„': [(20, 40)],
        'ç´«': [(130, 160)],
        'ã‚ªãƒ¬ãƒ³ã‚¸': [(10, 20)],
    }
    
    # ãƒã‚¹ã‚¯ã®ä½œæˆ
    mask = np.zeros(h.shape, dtype=bool)
    
    for h_range in color_ranges[target_color]:
        h_min, h_max = h_range
        mask |= ((h >= h_min) & (h <= h_max) & (s >= 100) & (v >= 100))
    
    # çµæœç”»åƒã®ä½œæˆ
    result = img_array.copy()
    result[~mask] = result[~mask] // 3  # å¯¾è±¡å¤–ã®è‰²ã‚’æš—ãã™ã‚‹
    
    return Image.fromarray(result)

def enhance_contrast(image, target_colors):
    """è¤‡æ•°ã®è‰²ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã‚’å¼·èª¿"""
    img_array = np.array(image)
    hsv = rgb_to_hsv(img_array)
    h, s, v = hsv[..., 0], hsv[..., 1], hsv[..., 2]
    
    result = img_array.copy()
    
    for mapping in target_colors:
        if mapping == 'èµ¤â†’ãƒã‚¼ãƒ³ã‚¿':
            # èµ¤ã®ç¯„å›²
            mask1 = ((h >= 0) & (h <= 10) & (s >= 100) & (v >= 100))
            mask2 = ((h >= 170) & (h <= 180) & (s >= 100) & (v >= 100))
            mask = mask1 | mask2
            result[mask] = [255, 0, 255]  # ãƒã‚¼ãƒ³ã‚¿
            
        elif mapping == 'ç·‘â†’ã‚·ã‚¢ãƒ³':
            # ç·‘ã®ç¯„å›²
            mask = ((h >= 40) & (h <= 80) & (s >= 100) & (v >= 100))
            result[mask] = [0, 255, 255]  # ã‚·ã‚¢ãƒ³
            
        elif mapping == 'èµ¤â†’é’':
            # èµ¤ã®ç¯„å›²
            mask1 = ((h >= 0) & (h <= 10) & (s >= 100) & (v >= 100))
            mask2 = ((h >= 170) & (h <= 180) & (s >= 100) & (v >= 100))
            mask = mask1 | mask2
            result[mask] = [0, 0, 255]  # é’
            
        elif mapping == 'ç·‘â†’é»„':
            # ç·‘ã®ç¯„å›²
            mask = ((h >= 40) & (h <= 80) & (s >= 100) & (v >= 100))
            result[mask] = [255, 255, 0]  # é»„è‰²
    
    return Image.fromarray(result)

def apply_daltonization(image, cvd_type):
    """è‰²è¦šç•°å¸¸ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨è£œæ­£"""
    img_array = np.array(image).astype(float) / 255.0
    
    # å¤‰æ›è¡Œåˆ—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if cvd_type == '1å‹ï¼ˆèµ¤ï¼‰':
        # ãƒ—ãƒ­ã‚¿ãƒãƒ”ã‚¢ï¼ˆèµ¤éŒä½“æ¬ æï¼‰
        transform = np.array([
            [0.567, 0.433, 0.000],
            [0.558, 0.442, 0.000],
            [0.000, 0.242, 0.758]
        ])
    elif cvd_type == '2å‹ï¼ˆç·‘ï¼‰':
        # ãƒ‡ãƒ¥ãƒ¼ã‚¿ãƒãƒ”ã‚¢ï¼ˆç·‘éŒä½“æ¬ æï¼‰
        transform = np.array([
            [0.625, 0.375, 0.000],
            [0.700, 0.300, 0.000],
            [0.000, 0.300, 0.700]
        ])
    else:  # 3å‹ï¼ˆé’ï¼‰
        # ãƒˆãƒªã‚¿ãƒãƒ”ã‚¢ï¼ˆé’éŒä½“æ¬ æï¼‰
        transform = np.array([
            [0.950, 0.050, 0.000],
            [0.000, 0.433, 0.567],
            [0.000, 0.475, 0.525]
        ])
    
    # ç”»åƒã‚’å¤‰æ›
    h, w = img_array.shape[:2]
    img_flat = img_array.reshape(-1, 3)
    simulated_flat = np.dot(img_flat, transform.T)
    simulated = simulated_flat.reshape(h, w, 3)
    
    # è£œæ­£ï¼ˆå·®åˆ†ã‚’å¼·èª¿ï¼‰
    error = img_array - simulated
    corrected = img_array + error * 1.5
    corrected = np.clip(corrected, 0, 1)
    
    return Image.fromarray((corrected * 255).astype(np.uint8))

# Streamlitã‚¢ãƒ—ãƒª
st.title('ğŸ¨ è‰²è¦šç•°å¸¸æ”¯æ´ãƒ„ãƒ¼ãƒ«')
st.write('ç”»åƒã®è‰²ã‚’åˆ†é›¢ãƒ»å¼·èª¿ã—ã¦ã€è‰²ã®è­˜åˆ¥ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™')

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header('è¨­å®š')
mode = st.sidebar.radio(
    'å‡¦ç†ãƒ¢ãƒ¼ãƒ‰',
    ['è‰²ã®åˆ†é›¢', 'ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿', 'è‰²è¦šè£œæ­£']
)

# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader('ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰', type=['png', 'jpg', 'jpeg'])

if uploaded_file:
    image = Image.open(uploaded_file).convert('RGB')
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader('å…ƒç”»åƒ')
        st.image(image, use_container_width=True)
    
    with col2:
        st.subheader('å‡¦ç†å¾Œ')
        
        if mode == 'è‰²ã®åˆ†é›¢':
            target = st.sidebar.selectbox(
                'åˆ†é›¢ã™ã‚‹è‰²',
                ['èµ¤', 'ç·‘', 'é’', 'é»„', 'ç´«', 'ã‚ªãƒ¬ãƒ³ã‚¸']
            )
            result = separate_colors(image, target)
            st.image(result, use_container_width=True)
            st.info(f'{target}è‰²ã®é ˜åŸŸã‚’å¼·èª¿è¡¨ç¤ºã—ã¦ã„ã¾ã™')
            
        elif mode == 'ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿':
            mappings = st.sidebar.multiselect(
                'è‰²ã®å¤‰æ›',
                ['èµ¤â†’ãƒã‚¼ãƒ³ã‚¿', 'ç·‘â†’ã‚·ã‚¢ãƒ³', 'èµ¤â†’é’', 'ç·‘â†’é»„'],
                default=['èµ¤â†’ãƒã‚¼ãƒ³ã‚¿']
            )
            if mappings:
                result = enhance_contrast(image, mappings)
                st.image(result, use_container_width=True)
                st.info('é¸æŠã—ãŸè‰²ã‚’è­˜åˆ¥ã—ã‚„ã™ã„è‰²ã«å¤‰æ›ã—ã¦ã„ã¾ã™')
            else:
                st.image(image, use_container_width=True)
                
        else:  # è‰²è¦šè£œæ­£
            cvd = st.sidebar.selectbox(
                'è‰²è¦šç•°å¸¸ã®ã‚¿ã‚¤ãƒ—',
                ['1å‹ï¼ˆèµ¤ï¼‰', '2å‹ï¼ˆç·‘ï¼‰', '3å‹ï¼ˆé’ï¼‰']
            )
            result = apply_daltonization(image, cvd)
            st.image(result, use_container_width=True)
            st.info(f'{cvd}è‰²è¦šç•°å¸¸ã«å¯¾å¿œã—ãŸè£œæ­£ã‚’é©ç”¨ã—ã¦ã„ã¾ã™')
    
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    if 'result' in locals():
        from io import BytesIO
        buf = BytesIO()
        result.save(buf, format='PNG')
        byte_im = buf.getvalue()
        
        st.download_button(
            'ğŸ’¾ å‡¦ç†ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰',
            byte_im,
            file_name='processed_image.png',
            mime='image/png'
        )

else:
    st.info('ğŸ‘† ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„')
    
# èª¬æ˜
with st.expander('â„¹ï¸ å„ãƒ¢ãƒ¼ãƒ‰ã®èª¬æ˜'):
    st.markdown('''
    **è‰²ã®åˆ†é›¢**: ç‰¹å®šã®è‰²ã ã‘ã‚’å¼·èª¿è¡¨ç¤ºã—ã€ä»–ã®è‰²ã‚’æš—ãã™ã‚‹ã“ã¨ã§è‰²ã®è­˜åˆ¥ã‚’å®¹æ˜“ã«ã—ã¾ã™
    
    **ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿**: æ··åŒã—ã‚„ã™ã„è‰²ã‚’ã€ã‚ˆã‚Šè­˜åˆ¥ã—ã‚„ã™ã„è‰²ã«å¤‰æ›ã—ã¾ã™
    - èµ¤â†’ãƒã‚¼ãƒ³ã‚¿: èµ¤ã‚’é®®ã‚„ã‹ãªãƒã‚¼ãƒ³ã‚¿ã«
    - ç·‘â†’ã‚·ã‚¢ãƒ³: ç·‘ã‚’æ˜ã‚‹ã„ã‚·ã‚¢ãƒ³ã«
    - èµ¤â†’é’: èµ¤ã‚’é’ã«å¤‰æ›ï¼ˆèµ¤ç·‘æ··åŒå¯¾ç­–ï¼‰
    - ç·‘â†’é»„: ç·‘ã‚’æ˜ã‚‹ã„é»„è‰²ã«
    
    **è‰²è¦šè£œæ­£**: è‰²è¦šç•°å¸¸ã®ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè£œæ­£ã‚’é©ç”¨ã—ã€è‰²ã®é•ã„ã‚’å¼·èª¿ã—ã¾ã™
    - 1å‹ï¼ˆèµ¤ï¼‰: èµ¤éŒä½“ã®æ©Ÿèƒ½ä¸å…¨
    - 2å‹ï¼ˆç·‘ï¼‰: ç·‘éŒä½“ã®æ©Ÿèƒ½ä¸å…¨ï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ï¼‰
    - 3å‹ï¼ˆé’ï¼‰: é’éŒä½“ã®æ©Ÿèƒ½ä¸å…¨
    ''')